import json
import asyncio
import time
from core.providers.tts.dto.dto import SentenceType
from core.utils.util import get_string_no_punctuation_or_emoji, analyze_emotion
from loguru import logger

TAG = __name__

emoji_map = {
    "neutral": "ğŸ˜¶",
    "happy": "ğŸ™‚",
    "laughing": "ğŸ˜†",
    "funny": "ğŸ˜‚",
    "sad": "ğŸ˜”",
    "angry": "ğŸ˜ ",
    "crying": "ğŸ˜­",
    "loving": "ğŸ˜",
    "embarrassed": "ğŸ˜³",
    "surprised": "ğŸ˜²",
    "shocked": "ğŸ˜±",
    "thinking": "ğŸ¤”",
    "winking": "ğŸ˜‰",
    "cool": "ğŸ˜",
    "relaxed": "ğŸ˜Œ",
    "delicious": "ğŸ¤¤",
    "kissy": "ğŸ˜˜",
    "confident": "ğŸ˜",
    "sleepy": "ğŸ˜´",
    "silly": "ğŸ˜œ",
    "confused": "ğŸ™„",
}


async def sendAudioMessage(conn, sentenceType, audios, text):
    # å‘é€å¥å­å¼€å§‹æ¶ˆæ¯
    conn.logger.bind(tag=TAG).info(f"å‘é€éŸ³é¢‘æ¶ˆæ¯: {sentenceType}, {text}")
    """
    if text is not None:
        emotion = analyze_emotion(text)
        emoji = emoji_map.get(emotion, "ğŸ™‚")  # é»˜è®¤ä½¿ç”¨ç¬‘è„¸
        await conn.websocket.send(
            json.dumps(
                {
                    "type": "llm",
                    "text": emoji,
                    "emotion": emotion,
                    "session_id": conn.session_id,
                }
            )
        )
    """
    pre_buffer = False
    if conn.tts.tts_audio_first_sentence and text is not None:
        conn.logger.bind(tag=TAG).info(f"å‘é€ç¬¬ä¸€æ®µè¯­éŸ³: {text}")
        conn.tts.tts_audio_first_sentence = False
        pre_buffer = True

    st = time.time() 
    text = ""
    await send_tts_message(conn, "sentence_start", text)
    # print("sending audio time 1: ", time.time() - st, sentenceType, conn.llm_finish_task, flush=True)

    await sendAudio(conn, audios, pre_buffer)
    # print("sending audio time 2: ", time.time() - st, len(audios), flush=True)

    await send_tts_message(conn, "sentence_end", text)
    # print("sending audio time 3: ", time.time() - st, flush=True)

    # å‘é€ç»“æŸæ¶ˆæ¯ï¼ˆå¦‚æœæ˜¯æœ€åä¸€ä¸ªæ–‡æœ¬ï¼‰
    if conn.llm_finish_task and sentenceType == SentenceType.LAST:
        # #æ¸…ç©ºéŸ³é¢‘ç¼“å†²æµ
        # conn.asr_audio.clear()
        # #æ¸…ç©ºASRéŸ³é¢‘é˜Ÿåˆ—
        # while not conn.asr_audio_queue.empty():
        #     try:
        #         conn.asr_audio_queue.get_nowait()
        #     except asyncio.QueueEmpty:
        #         break
        # #é‡ç½®VADçŠ¶æ€
        # conn.reset_vad_states()
        # conn.logger.bind(tag=TAG).info(f"å·²æ¸…ç©ºéŸ³é¢‘ç¼“å†²é˜Ÿåˆ—ï¼Œåˆ‡æ¢åˆ°è¯´è¯çŠ¶æ€")
        await send_tts_message(conn, "stop", None)
        conn.client_is_speaking = False
        if conn.close_after_chat:
            print("close conn after chat... ", time.time()-st, flush=True)
            await conn.close()


# æ’­æ”¾éŸ³é¢‘
async def sendAudio(conn, audios, pre_buffer=True):
    if audios is None or len(audios) == 0:
        return
    # æµæ§å‚æ•°ä¼˜åŒ–
    frame_duration = 60  # å¸§æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰ï¼ŒåŒ¹é… Opus ç¼–ç 
    start_time = time.perf_counter()
    play_position = 0

    # ä»…å½“ç¬¬ä¸€å¥è¯æ—¶æ‰§è¡Œé¢„ç¼“å†²
    if pre_buffer:
        pre_buffer_frames = min(3, len(audios))
        for i in range(pre_buffer_frames):
            await conn.websocket.send(audios[i])
        remaining_audios = audios[pre_buffer_frames:]
    else:
        remaining_audios = audios

    # æ’­æ”¾å‰©ä½™éŸ³é¢‘å¸§
    for opus_packet in remaining_audios:
        if conn.client_abort:
            print("client abort while sending audio", flush=True)
            break

        # é‡ç½®æ²¡æœ‰å£°éŸ³çš„çŠ¶æ€
        conn.last_activity_time = time.time() * 1000

        # è®¡ç®—é¢„æœŸå‘é€æ—¶é—´
        expected_time = start_time + (play_position / 1000)
        current_time = time.perf_counter()
        delay = expected_time - current_time
        if delay > 0:
            await asyncio.sleep(delay)

        await conn.websocket.send(opus_packet)

        play_position += frame_duration


async def send_tts_message(conn, state, text=None):
    """å‘é€ TTS çŠ¶æ€æ¶ˆæ¯"""
    message = {"type": "tts", "state": state, "session_id": conn.session_id}
    if text is not None:
        message["text"] = text

    if state == "start":
        conn.set_state_assistant_speaking()
    elif state in ("stop", "abort"):
        conn.set_state_idle()

    await conn.websocket.send(json.dumps(message,separators=(",", ":")))


async def send_stt_message(conn, text):
    conn.client_is_speaking = True
    conn.set_state_user_speaking()
    await send_tts_message(conn, "start")
